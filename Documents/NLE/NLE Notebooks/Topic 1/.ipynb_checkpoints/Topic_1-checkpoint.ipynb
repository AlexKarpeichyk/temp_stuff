{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic 1: Preprocessing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries \n",
    "Run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r'\\\\ad.susx.ac.uk\\ITS\\TeachingResources\\Departments\\Informatics\\LanguageEngineering\\resources')\n",
    "import re\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import collections\n",
    "from collections import defaultdict,Counter\n",
    "from itertools import zip_longest\n",
    "from IPython.display import display\n",
    "from random import seed\n",
    "get_ipython().magic('matplotlib inline')\n",
    "import random\n",
    "import math\n",
    "import matplotlib.pylab as pylab\n",
    "%matplotlib inline\n",
    "params = {'legend.fontsize': 'large',\n",
    "          'figure.figsize': (15, 5),\n",
    "         'axes.labelsize': 'large',\n",
    "         'axes.titlesize':'large',\n",
    "         'xtick.labelsize':'large',\n",
    "         'ytick.labelsize':'large'}\n",
    "pylab.rcParams.update(params)\n",
    "from pylab import rcParams\n",
    "from operator import itemgetter, attrgetter, methodcaller\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview \n",
    "A raw text document is just a sequence of characters. There are a number of basic steps that are often performed when processing natural language text. In this lab session we will cover some of the basic text pre-processing methods. In particular, you will be looking at:\n",
    "- <b> tokenisation</b> - roughly speaking, this involves grouping characters into words;\n",
    "- <b>case normalisation</b> - this involves converting all of the text into lower case; \n",
    "- <b>stemming</b> - this involves removing a word's inflections to find the stem; and \n",
    "- <b>punctuation and stop-word removal</b> - stop-words are common functions words that in some situations can be ignored.\n",
    "\n",
    "Note that we do not always apply all of the above preprocessing methods; it depends on the application. One of the things that you will be learning about in this module, is when the application of each of these methods is, and is not, appropriate."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Available corpora\n",
    "We have provided simple interfaces to each of the following corpora, which interact well with NLTK tools.\n",
    "\n",
    "- The NLTK texts\n",
    "- Amazon product reviews (~78k documents, ~640k sentences)\n",
    "- Wall Street Journal text (~2k documents, ~51k sentences)\n",
    "- Reuters articles (~61k documents, ~740k sentences)\n",
    "  - Reuters / Finance (~47k documents, ~550k sentences)\n",
    "  - Reuters / Sport (~13k documents, ~185k sentences)\n",
    "- Medline abstracts (~985k documents, ~6100k sentences)\n",
    "- Twitter posts (~962k documents, ~1720k sentences)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting raw sentences from a corpus\n",
    "The corpora are too large to easily process with some of the functions you will be using, so we have provided a way for you to work on a randomly selected sample of each corpus.\n",
    "\n",
    "The Reuters, Twitter and Medline corpora have a function called <code style=\"background-color: #F5F5F5;\">sample_raw_sents</code>, which returns a specified number of random sentences, where each sentence is an un-tokenised string.\n",
    "\n",
    "The code in the next cell shows you how to iterate over a random sample of 10 sentences. When you are using a tokeniser, you will replace\n",
    "`# do something with sentence`\n",
    "with code that tokenises each sentence and prints the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "unexpected EOF while parsing (<ipython-input-2-992bca363b32>, line 10)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-2-992bca363b32>\"\u001b[1;36m, line \u001b[1;32m10\u001b[0m\n\u001b[1;33m    # do something with sentence\u001b[0m\n\u001b[1;37m                                ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m unexpected EOF while parsing\n"
     ]
    }
   ],
   "source": [
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "\n",
    "rcr = ReutersCorpusReader()    #Create a new reader\n",
    "\n",
    "sample_size = 10\n",
    "\n",
    "candidate_number = 123456\n",
    "\n",
    "for sentence in rcr.sample_raw_sents(sample_size): #get a sample of random sentences, where each sentence is a string\n",
    "    # do something with sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Make a copy the cell above and move the copied cell so that it is positioned below this cell. \n",
    "- Adapt the code in the new cell so that it prints a sample of **20** sentences from the **Twitter** corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sussex NLTK root directory is \\\\ad.susx.ac.uk\\ITS\\TeachingResources\\Departments\\Informatics\\LanguageEngineering\\resources\n",
      "New google doodle is fun! They've really upped their game for #olympics2012 #awfulpun\n",
      "@KimConley amazing job in the 5K Semi-Finals at The Olympics\n",
      "These brothers are freaking awesome #TeamGB #Triathlon\n",
      "Imagine if all the Caribbean islands united as a team for the Olympics. The domination would be like China with the Indoor events.\n",
      "This pretty much sums it up the feelings of a nation. @cathalkelly terrific piece on last night's soccer game.  http://t.co/xxBXWAVJ\n",
      "Ma watching Olympics women's volleyball. Says she used to play. I is amazed. Pa says they used to play on same team in uni. LAGI AMAZED.\n",
      "GG lagi ning CHINA WOMEN'S VOLLEYBALL TEAM :X   #olympics\n",
      "It looks like Water Polo's version of a footy dive is to reenact the opening scene of Jaws. #london2012\n",
      "These male #gymnasts have me all sorts of hot and bothered #Olympics\n",
      "#London2012 Penalty corner to Argentina, they hit back immediately to lead by three goals once again. It's 6-3 with four mins to play.\n",
      "ぐんまちゃんとは恋愛ゼロ！友情百パーセント！ RT @Koringo_jp:  熱愛発覚！ よみがえる神の手 ／ 写真合成アプリで、オリンピックを応援！ http://t.co/expquVI3 #yjolympic_app http://t.co/2vcVNZcz\n",
      "(*_*)　　ｗｗ　　フェルプス「みんなプールで放尿してる」 - 競泳 http://t.co/HLuU1M39 @nikkan_Olympicさんから\n",
      "Whenever the olympics are on my parents seem to force us into exercise because my tumblr followers apparently isn't enough :P\n",
      "RT @powerplate: Its official, #TeamGB are the most successful GB Olympic team in history, 20 gold medals and counting #OurGreatestTeam\n",
      "Well done Laura Trott!! #TeamGB ????????????????????\n",
      "@RealKurtAngle aug.10 is freestyle start I think. Greco is all but done. #London2012\n",
      "RT @HilariousPost: Me watching Olympics: Woah! That was outstanding! Announcer: Another devastating mistake!\n",
      "All I've done over here is watch the Olympics or swim lengths in our pool:L\n",
      "South Korea vs Brazil semifinal olympic #london2012\n",
      "My Dad had his hip replaced today. He had it done under local anaesthetic & not general! Watched the Olympics all the way through it!#nutter\n"
     ]
    }
   ],
   "source": [
    "from sussex_nltk.corpus_readers import TwitterCorpusReader\n",
    "\n",
    "tcr = TwitterCorpusReader()    #Create a new reader\n",
    "\n",
    "sample_size = 20\n",
    "\n",
    "for sentence in tcr.sample_raw_sents(sample_size): #get a sample of random sentences, where each sentence is a string\n",
    "    print(sentence)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Point your browser at [Sussex NLTK package documentation](http://www.sussex.ac.uk/Users/davidw/courses/nle/SussexNLTK-API/) and have a look around. This provides information about the above corpora. Take a particularly careful look at the [corpus_readers Module](http://www.sussex.ac.uk/Users/davidw/courses/nle/SussexNLTK-API/sussex_nltk.html#module-sussex_nltk.corpus_readers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- In the code cell below write code that will establish whether there are systematic differences between the  average sentence length (as measured in terms of the number of characters in the sentence) of the sentences in the Reuters, Twitter and Medline corpora."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Corpus</th>\n",
       "      <th>ASL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Reuters</td>\n",
       "      <td>14.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Twitter</td>\n",
       "      <td>14.496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Medline</td>\n",
       "      <td>22.024</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Corpus     ASL\n",
       "0  Reuters  14.579\n",
       "1  Twitter  14.496\n",
       "2  Medline  22.024"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "from sussex_nltk.corpus_readers import TwitterCorpusReader\n",
    "from sussex_nltk.corpus_readers import MedlineCorpusReader\n",
    "\n",
    "rcr = ReutersCorpusReader()\n",
    "tcr = TwitterCorpusReader()\n",
    "mcr = MedlineCorpusReader()\n",
    "\n",
    "sample_size = 1000\n",
    "\n",
    "R = 0\n",
    "T = 0\n",
    "M = 0\n",
    "\n",
    "for sentence in rcr.sample_raw_sents(sample_size):\n",
    "    R += len(sentence.split())\n",
    "for sentence in tcr.sample_raw_sents(sample_size):\n",
    "    T += len(sentence.split())\n",
    "for sentence in mcr.sample_raw_sents(sample_size):\n",
    "    M += len(sentence.split())\n",
    "    \n",
    "ASL_R = R/sample_size\n",
    "ASL_T = T/sample_size\n",
    "ASL_M = M/sample_size\n",
    "\n",
    "ddict = {\"Corpus\": [\"Reuters\", \"Twitter\", \"Medline\"], \"ASL\": [ASL_R, ASL_T, ASL_M]}\n",
    "\n",
    "display(pd.DataFrame(ddict, columns = [\"Corpus\", \"ASL\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment the next line and then run the cell to load a partial solution\n",
    "#%load solutions/average_sentence_length_part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/average_sentence_length\n",
    "from sussex_nltk.corpus_readers import MedlineCorpusReader\n",
    "from sussex_nltk.corpus_readers import TwitterCorpusReader\n",
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "\n",
    "rcr = ReutersCorpusReader()    #Create a new reader\n",
    "tcr = TwitterCorpusReader()    #Create a new reader\n",
    "mcr = MedlineCorpusReader()    #Create a new reader\n",
    "\n",
    "samplesize = 1000\n",
    "\n",
    "TSL_R = 0 #initialise reuters total sentence length variable\n",
    "TSL_T = 0 #initialise twitter total sentence length variable\n",
    "TSL_M = 0 #initialise medline total sentence length variable\n",
    "   \n",
    "for sentence in rcr.sample_raw_sents(samplesize): \n",
    "    TSL_R += len(sentence)\n",
    "for sentence in tcr.sample_raw_sents(samplesize): \n",
    "    TSL_T += len(sentence)\n",
    "for sentence in mcr.sample_raw_sents(samplesize): \n",
    "    TSL_M += len(sentence)\n",
    "\n",
    "ASL_Reuters = TSL_R/samplesize\n",
    "ASL_Twitter = TSL_T/samplesize\n",
    "ASL_Medline = TSL_M/samplesize\n",
    "\n",
    "# A Pandas dataframe is a convenient way to display the average sentence length (ASL) of each corpus in a table. \n",
    " \n",
    "# Create a dictionary.\n",
    "# There is a key for each column - in this we have two columns 'Corpus' and 'ASL'\n",
    "# The values of each key is a list of the values for each row of the corresponding column.\n",
    "# The lists need to have the same length, corresponding to the number of rows in the table.\n",
    "\n",
    "datadict = {'Corpus' : ['Reuters','Twitter','Medline'],\n",
    "            'ASL' : [ASL_Reuters,ASL_Twitter,ASL_Medline]}\n",
    "\n",
    "# Make a dataframe from the dictionary.\n",
    "# The columns parameters allows us to specify the order of the columns.\n",
    "# By default the columns would appear in alphabetical order of their key.\n",
    "\n",
    "df = pd.DataFrame(datadict,columns=['Corpus','ASL'])\n",
    "\n",
    "display(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DIY Tokenisation with Regular Expressions\n",
    "Text doesn't come in neat tokens ready for analysis, it must first undergo sentence segmentation and tokenisation.  \n",
    "We have already sentence segmented the corpora.  \n",
    "In this lab you will be focusing on tokenisation, in particular, you will be comparing the merits of the following tokenisers:  \n",
    "- Your own regular expression based tokeniser\n",
    "- The (NLTK implemented) PENN treebank style regular expression based tokeniser\n",
    "- A Twitter-specific CMU tokeniser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues to consider\n",
    "Your goal when working through this next section should be to investigate the strengths and weaknesses of each of the 3 tokenisers on three rather different kinds of corpora: \n",
    "- the Reuters corpus, \n",
    "- the Twitter corpus and \n",
    "- the Medline corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making your own tokeniser\n",
    "In this section, you will write your own Python function, which takes as input a single string representing a sentence, and returns a <b>list of strings</b> obtained by splitting the sentence into tokens.\n",
    "\n",
    "Let's start by simply splitting by whitespace. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'the', 'air-speed', 'velocity', 'of', 'an', 'unladen', 'swallow?']\n"
     ]
    }
   ],
   "source": [
    "print(\"   What    is the    air-speed   velocity of  an unladen swallow?   \".split()) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- In the empty code cell below write a [function](http://docs.python.org/tutorial/controlflow.html#defining-functions), `tokenise` which takes a sentence as input and returns a list of the tokens making up the sentence. Your first version of this function should tokenise only on whitespace, as shown in the cell above. Show that your function works on the sentence shown above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenise(text):\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['What', 'is', 'the', 'air-speed', '.', 'velocity', 'of', 'an', 'unladen', 'swallow?']\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/simple_tokenise\n",
    "def tokenise(sentence):\n",
    "    return sentence.split()\n",
    "\n",
    "print(tokenise(' What is the    air-speed . velocity of  an unladen swallow?   '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- In the empty code cell below write code that applies your tokenise function to each sentence in a sample of 30 sentences taken from  the Reuters, Twitter and Medline corpora, 10 sentences from each corpus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['DELIVERY:', '45', 'days', 'ORDERS:']\n",
      "['SUMMARY', 'NOTICE', 'OF', 'SALE']\n",
      "['But', 'on', 'Monday,', 'confusion', 'surrounded', 'the', 'plan,', 'depositors', 'amd', 'company', 'officials', 'said.']\n",
      "['Downey', 'Unified', 'School', 'District']\n",
      "['PSP', '=', 'Postipankki', '(May', '27)']\n",
      "['PSBR', '(in', 'million', 'stg)', 'APRIL', 'MARCH', 'APRIL', '96']\n",
      "['--$21.039', 'million', 'Plain', 'LSD,', 'G.O.']\n",
      "['A', 'booming', 'U.S.', 'economy', 'drew', 'in', 'record', 'imports', 'during', 'February,', 'the', 'Commerce', 'Department', 'said', 'on', 'Thursday,', 'slowing', 'improvement', 'in', 'the', 'monthly', 'deficit', 'and', 'spotlighting', 'trade', 'tensions', 'with', 'China.']\n",
      "['The', 'tax', 'bill', 'includes', 'a', '$500-per-child', 'credit,', 'a', 'reduction', 'in', 'the', 'capital', 'gains', 'rate', 'and', 'new', 'tax', 'incentives', 'for', 'for', 'higher', 'education.']\n",
      "['Analysts', 'and', 'politicians', 'agreed', 'the', 'cachet', 'of', 'membership', 'in', 'exclusive', 'Western', 'clubs', 'like', 'the', 'EU', 'and', 'NATO', 'would', 'carry', 'great', 'economic', 'weight,', 'boosting', 'foreign', 'investment', 'and', 'raising', 'confidence.']\n",
      "['Goldie', 'Sayers', 'is', 'beginning', 'her', 'quest', 'for', 'as', 'Olympic', 'medal', 'as', 'she', 'starts', 'her', 'javelin', 'qualification.', '#London2012']\n",
      "['@usainbolt', 'Good', 'luck', 'today', 'sir,', 'hopefully', 'u', 'can', 'set', 'up', 'a', 'GOLD', 'once', 'Olympics', 'are', 'done,', 'it', 'would', 'be', 'great', 'to', 'see', 'you', 'have', 'a', 'trial', 'at', 'UNITED']\n",
      "['USA', 'vs', 'Canada', 'live', 'Game', 'streaming', '2012', 'Summer', 'Olympics', 'Basketball', 'online', 'Cast:', 'DEAR,You', 'are', 'most', 'welcome', 'to', 'watc...', 'http://t.co/oKsNc9dM']\n",
      "['maç', 'bitmeyecek', ':)', '#London2012']\n",
      "['I', 'love', 'that', 'the', 'closer', 'and', 'higher-stakes', 'a', '#waterpolo', 'game', 'is,', 'the', 'more', 'like', 'super-violent', 'water', 'wrestling', 'it', 'becomes.', '#London2012', '#Olympics']\n",
      "['Nothing', 'quite', 'like', 'a', 'big', 'tough', 'man', 'having', 'a', 'weep', ':-)', 'Sir', 'Chris', 'Hoy', '-', 'a', 'proper', 'legend,', 'and', 'such', 'a', 'nice', 'chap!', '#TeamGB', '#Olympics2012']\n",
      "['Now', \"it's\", 'time', 'for', 'the', 'USA', \"Women's\", 'Volleyball', 'team', 'to', 'do', 'their', 'thing!', '#olympics']\n",
      "['Andrew', 'osagie', ';)', 'hello!', '#teamGB']\n",
      "['RT', '@Bolanet:', '#LONDON2012', '-', 'Perebutan', 'medali', 'perunggu', '(11/8)', '-', 'Korsel', 'v', 'Jepang', '-', '1.45WIB', 'LIVE', 'RCTI']\n",
      "['As', 'Olympics', 'action', 'winds', 'down', 'for', 'the', 'day', 'you', 'can', 'win', 'Premier', 'League', 'tickets', 'for', 'Chelsea', 'v', 'Newcastle-', 'http://t.co/ssHrHeZo']\n",
      "['Strong', 'phosphatase', 'activity', 'is', 'seen', 'throughout', 'the', 'cells,', 'especially', 'around', 'the', 'nucleus', 'and', 'cell', 'membrane.']\n",
      "['Performance', 'depends', 'sensitively', 'on', 'a', '\"symbiotic\"', 'interaction', 'between', 'agronomy', 'and', 'technology.']\n",
      "['We', 'have', 'carried', 'out', 'clinical,', 'radiological', 'and', 'some', 'hematological', 'evaluation', 'of', 'post-traumatic', 'subgaleal', 'hematoma', 'in', '55', 'Nigerians', 'who', 'were', 'treated', 'for', 'head', 'injuries', 'at', 'the', 'he', 'University', 'College', 'Hospital,', 'Ibadan,', 'Nigeria,', 'in', '1970.']\n",
      "['Relative', 'resistance', 'to', 'erythromycin', 'was', 'detected;', 'two', 'isolates', 'were', 'capable', 'of', 'limited', 'replication', 'in', '1', 'microgram/ml.']\n",
      "['After', 'these', 'groups', 'the', 'participants', 'stated', 'that', 'they', 'had', 'experienced', 'relief', 'in', 'their', 'dissatisfaction', 'with', 'own', 'behaviour', 'and', 'emotional', 'problems.']\n",
      "['Haloperidol', 'was', 'more', 'effective', 'than', 'benzquinamide', '(54', 'vs.', '29%)', 'in', 'patients', 'previously', 'unrelieved', 'by', 'prochlorperazine', '(Compazine).']\n",
      "['This', 'observation', 'combined', 'with', 'earlier', 'studies', 'on', 'the', 'human', 'lung', 'mast', 'cell,', 'which', 'also', 'failed', 'to', 'demonstrate', 'that', 'histamine', 'had', 'an', 'inhibitory', 'action,', 'suggests', 'that', 'the', 'human', 'mast', 'cell', 'may', 'not', 'respond', 'to', 'histamine', 'like', 'the', 'basophil', 'and', 'that', 'this', 'discrepancy', 'may', 'represent', 'a', 'fundamental', 'difference', 'in', 'the', 'cell', 'types.']\n",
      "['The', 'metabolites', 'of', 'DCHP,', 'namely', 'monocyclohexyl', 'phthalate', '(MCHP)', 'and', 'cyclohexanol,', 'also', 'induced', 'certain', 'parameters', 'of', 'hepatic', 'xenobiotic', 'metabolism.']\n",
      "['For', 'Proteus', 'mirabilis', '(n', '=', '69)', 'and', 'indole-positive', 'Proteus', 'species', '(n', '=', '23),', 'the', 'tube', 'dilution', 'test', 'was', 'used.']\n",
      "['Hamsters', 'of', 'the', 'deficient', 'group', 'exhibited', 'clinical', 'and', 'morphologic', 'changes', 'characteristic', 'of', 'vitamin', 'A', 'deficiency.']\n"
     ]
    }
   ],
   "source": [
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "from sussex_nltk.corpus_readers import TwitterCorpusReader\n",
    "from sussex_nltk.corpus_readers import MedlineCorpusReader\n",
    "\n",
    "rcr = ReutersCorpusReader()\n",
    "tcr = TwitterCorpusReader()\n",
    "mcr = MedlineCorpusReader()\n",
    "\n",
    "sent = 10\n",
    "\n",
    "for sentence in rcr.sample_raw_sents(sent):\n",
    "    print(tokenise(sentence))\n",
    "for sentence in tcr.sample_raw_sents(sent):\n",
    "    print(tokenise(sentence))\n",
    "for sentence in mcr.sample_raw_sents(sent):\n",
    "    print(tokenise(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment the next line and then run the cell to load a solution\n",
    "# %load solutions/tokenise_samples"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In most tokenisation policies (e.g. in the Wall Street Journal corpus), contractions like \"I'm\" tend to be split into \"I\" and \"'m\".  \n",
    "\n",
    "When it comes to more than just splitting by whitespace, it can be convenient to use [regular expressions](http://docs.python.org/library/re.html) to process the string in some way. The following code cell illustrates this. Trying running it and then read on to discover how it works."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You', \"'re\", 'using', 'coconuts', '!']\n"
     ]
    }
   ],
   "source": [
    "print(re.sub(\"([.?!'])\", \" \\g<1>\", \"You're using coconuts!\").split())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at how the above code works by breaking it down.  \n",
    "\n",
    "First, run the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You 're using coconuts!\n"
     ]
    }
   ],
   "source": [
    "print(re.sub(\"'\", \" '\", \"You're using coconuts!\")   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, this code takes the string \"You're using coconuts!\" and inserts a space before the apostophe, the `'` character. \n",
    "\n",
    "Let's see how it works...\n",
    "\n",
    "The first argument of `re.sub`, i.e. `\"'\"`, is a regular expression that in this case is extremely simple, since it only matches the apostophe character, `'`.\n",
    "\n",
    "The second argument of `re.sub`, where we see `\" '\"`, indicates that an apostophe should be substituted by a space followed by an apostophe.\n",
    "\n",
    "Now let's make it slightly more complicated. We also want to insert a space before the `\"!\"`, so let's look at how to do that. \n",
    "\n",
    "Run the following code cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You 're using coconuts !\n"
     ]
    }
   ],
   "source": [
    "print(re.sub(\"(['!])\", \" \\g<1>\", \"You're using coconuts!\")   )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first argument of `re.sub`, has been changed to `\"(['!])\"`, which is a regular expression that matches either an apostophe character,`'`, or an exclamation mark,`!`.\n",
    "\n",
    "This is achieved with the regular expression `\"['!]\"`, where the square brackets enclose the alternative characters. \n",
    "\n",
    "Why does the regular expression contain parenthesis? \n",
    "\n",
    "It has to do with what we need to put as the second argument of `re.sub` where the substitution is specified. \n",
    "\n",
    "To understand this, you need to appreciate that we want to add a space before an apostrophe and also a space before an exclamation mark. How can we specify that in the second argument of `re.sub`? \n",
    "\n",
    "The answer is that we need to make use of the the idea of a **group**.\n",
    "\n",
    "The parenthesis in `\"(['!])\"` define the start and end of a group. In this case the whole regular expression is a group. In general, however, there can be several sets of parentheis defining several groups. For example, the regular expression `\"([Tt]h)e (m*n)\"` has two groups. Groups are numbered from left to right, so the group in the regular expression `\"(['!])\"` is group 1. \n",
    "\n",
    "Defining this group allows us to refer to the string that matches the regular expression `\"(['!])\"`, which will be either an apostrophe or an exclamation mark. This is then used in the second argument of `re.sub`, where we see `\" \\g<1>\"`, which indicates that the material that matches the apostophe or exclamation mark should be substituted by a space followed by the symbol that was matched. The `1` in `\\g<1>` tells us that it is group one.\n",
    "\n",
    "We are now ready to look at the original code, which is reproduced below and should now make sense. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(re.sub(\"([.?!'])\", \" \\g<1>\", \"You're using /.coconuts!\").split())   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the spaces are added before any full stop, question mark, exclamation mark or apostrophe.\n",
    "The resulting string is then split on white space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Create an empty code cell below, and write a new version of your `tokenise` function that uses `re.sub` in the way we've just considered. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['You', \"'re\", 'using', 'coconuts', '!']\n"
     ]
    }
   ],
   "source": [
    "def token(string):\n",
    "    return re.sub(\"([.?!'])\", \" \\g<1>\", string).split()\n",
    "\n",
    "print(token(\"You're using coconuts!\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/tokenise_with_re.sub\n",
    "def tokenise(sentence):\n",
    "    return re.sub(\"([.?!'])\", \" \\g<1>\", sentence).split()\n",
    "\n",
    "print(tokenise(' What is the    air-speed . velocity of  an unladen swallow?   '))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "\n",
    "- Create an empty code cell below, and extend your tokeniser function to cater for the following guidelines. \n",
    "- Test out your new tokeniser on the string  \n",
    "`\"After saying \\\"I won't help, I'm gonna leave!\\\", on his parents' arrival, the boy's behaviour improved.\"`  \n",
    " notice that the `\"` characters in the test sentence have been espaced, appearing as `\\\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['I',\n",
       " 'wo',\n",
       " \"n't\",\n",
       " 'help',\n",
       " ',',\n",
       " 'I',\n",
       " \"'m\",\n",
       " 'gon',\n",
       " 'na',\n",
       " 'leave',\n",
       " '!',\n",
       " '\"',\n",
       " ',',\n",
       " 'on',\n",
       " 'his',\n",
       " 'parents',\n",
       " \"'\",\n",
       " 'arrival',\n",
       " ',',\n",
       " 'the',\n",
       " 'boy',\n",
       " \"'s\",\n",
       " 'behaviour',\n",
       " 'improved',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenise(\"I won't help, I'm gonna leave!\\\", on his parents' arrival, the boy's behaviour improved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Guidelines\n",
    "\n",
    "- punctuation is split from adjoining words\n",
    "- opening double quotes are changed to two single forward quotes.\n",
    "- closing double quotes are changed to two single backward quotes.\n",
    "- the Anglo-Saxon genitive of nouns are split into their component morphemes, and each morpheme is tagged separately.\n",
    "  - e.g. `\"children's\"` produces `\"children 's\"`\n",
    "  - e.g. `\"parents'\"` produces `\"parents '\"`\n",
    "- contractions should be split into component morphenes\n",
    "  - e.g. `\"won't\"` produces `\"wo n't\"`\n",
    "  - e.g. `\"gonna\"` produces `\"gon na\"`\n",
    "  - e.g. `\"I'm\"` produces `\"I 'm\"`\n",
    "  \n",
    "  \n",
    "These tokenisation guidelines are a subset of those found [here](http://www.cis.upenn.edu/~treebank/tokenization.html).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Hints:\n",
    "\n",
    "- Use multiple calls to `re.sub` to deal with different cases one at a time. As in...\n",
    "\n",
    "```\n",
    "    sentence = re.sub(<pattern1>, <replacement1>,sentence)\n",
    "    sentence = re.sub(<pattern2>, <replacement2>,sentence)\n",
    "    sentence = re.sub(<pattern3>, <replacement3>,sentence)\n",
    "```\n",
    "\n",
    "- Order your calls to `re.sub` so that you deal with the specific cases first and the more general cases later.\n",
    "\n",
    "- In dealing with the replacement of start and end `\"`, you will find the following useful:\n",
    "\n",
    ">The `'*'`, `'+'`, and `'?'` qualifiers are all *greedy*; they match\n",
    ">as much text as possible.  Sometimes this behaviour isn't desired; if the RE\n",
    ">`<.\\*>` is matched against `<a> b <c>`, it will match the entire\n",
    ">string, and not just `<a>`.  Adding `'?'` after the qualifier makes it\n",
    ">perform the match in *non-greedy* or *minimal* fashion; as *few*\n",
    ">characters as possible will be matched.  Using the RE `<.\\*?>` will match\n",
    ">only `<a>`.  \n",
    "(taken from https://docs.python.org/2/library/re.html).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['After', 'saying', '\"I', \"won't\", 'help,', 'I', \"'m\", 'gonna', 'leave!\",', 'on', 'his', \"parents'\", 'arrival,', 'the', 'boy', \"'s\", 'behaviour', 'improved.']\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/my_tokeniser\n",
    "import re    #import regex module\n",
    "\n",
    "def tokenise(sentence):\n",
    "    sentence = re.sub(\"'(s|m|(re)|(ve)|(ll)|(d))\\s\", \" '\\g<1> \",sentence + \" \")\n",
    "    #sentence = re.sub(\"s'\\s\", \"s ' \",sentence)\n",
    "    #sentence = re.sub(\"n't\\s\", \" n't \",sentence)\n",
    "    #sentence = re.sub(\"gonna\", \"gon na\",sentence)\n",
    "    #sentence = re.sub(\"\\\"(.+?)\\\"\", \"`` \\g<1> ''\",sentence)   \n",
    "    #sentence = re.sub(\"([.,?!])\", \" \\g<1> \", sentence)\n",
    "    return sentence.split()\n",
    "\n",
    "testsentence = \"After saying \\\"I won't help, I'm gonna leave!\\\", on his parents' arrival, the boy's behaviour improved.\"\n",
    "\n",
    "print(tokenise(testsentence))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load solutions/my_tokeniser\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The NLTK regular expression tokeniser\n",
    "The NLTK implements a regular expression tokeniser `word_tokenize` that is based on the above tokenisation guidelines. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Function**: `word_tokenize`\n",
    "\n",
    "- Arguments\n",
    " - a single string, representing a sentence\n",
    "- Returns\n",
    " - a list of strings, where each string is a token within the sentence</dd>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- Make sure you understand the code in the cell below and then run it so that you can compare the way that the test sentence has been tokensed by the two tokenisers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>After</td>\n",
       "      <td>After</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>saying</td>\n",
       "      <td>saying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>``</td>\n",
       "      <td>``</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wo</td>\n",
       "      <td>wo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>n't</td>\n",
       "      <td>n't</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>help</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>'m</td>\n",
       "      <td>'m</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>gon</td>\n",
       "      <td>gon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>na</td>\n",
       "      <td>na</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>leave</td>\n",
       "      <td>leave</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>!</td>\n",
       "      <td>!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>``</td>\n",
       "      <td>''</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>his</td>\n",
       "      <td>his</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>parents</td>\n",
       "      <td>parents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>'</td>\n",
       "      <td>'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>arrival</td>\n",
       "      <td>arrival</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>boy</td>\n",
       "      <td>boy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>'s</td>\n",
       "      <td>'s</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>behaviour</td>\n",
       "      <td>behaviour</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>improved</td>\n",
       "      <td>improved</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NLTK       MINE\n",
       "0       After      After\n",
       "1      saying     saying\n",
       "2          ``         ``\n",
       "3           I          I\n",
       "4          wo         wo\n",
       "5         n't        n't\n",
       "6        help       help\n",
       "7           ,          ,\n",
       "8           I          I\n",
       "9          'm         'm\n",
       "10        gon        gon\n",
       "11         na         na\n",
       "12      leave      leave\n",
       "13          !          !\n",
       "14         ``         ''\n",
       "15          ,          ,\n",
       "16         on         on\n",
       "17        his        his\n",
       "18    parents    parents\n",
       "19          '          '\n",
       "20    arrival    arrival\n",
       "21          ,          ,\n",
       "22        the        the\n",
       "23        boy        boy\n",
       "24         's         's\n",
       "25  behaviour  behaviour\n",
       "26   improved   improved\n",
       "27          .          ."
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "    \n",
    "testsentence = \"After saying \\\"I won't help, I'm gonna leave!\\\", on his parents' arrival, the boy's behaviour improved.\"\n",
    "\n",
    "# run the nltk tokeniser and your tokeniser on the test sentence\n",
    "nltk_toks = word_tokenize(testsentence) # run the nltk tokeniser\n",
    "my_toks = token(testsentence) # run your tokeniser\n",
    "\n",
    "pd.DataFrame(list(zip_longest(nltk_toks,my_toks)),columns=[\"NLTK\", \"MINE\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "\n",
    "- In the code cell below write code to run both the `NLTK_Tokenise` and your own `Tokenise` function on a sample of 10 sentences from the Reuters corpus.\n",
    "- Look for differences in the output of the two tokenisers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>02/01/2029</td>\n",
       "      <td>02/01/2029</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>41,360M</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.80</td>\n",
       "      <td>,360M</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>%</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>None</td>\n",
       "      <td>.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>None</td>\n",
       "      <td>%</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NLTK        MINE\n",
       "0  02/01/2029  02/01/2029\n",
       "1     41,360M          41\n",
       "2        5.80       ,360M\n",
       "3           %           5\n",
       "4        None         .80\n",
       "5        None           %"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Lawmaker</td>\n",
       "      <td>Lawmaker</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Kim</td>\n",
       "      <td>Kim</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Young-jin</td>\n",
       "      <td>Young-jin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>main</td>\n",
       "      <td>main</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>opposition</td>\n",
       "      <td>opposition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>National</td>\n",
       "      <td>National</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Congress</td>\n",
       "      <td>Congress</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>for</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>New</td>\n",
       "      <td>New</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Politics</td>\n",
       "      <td>Politics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>leader</td>\n",
       "      <td>leader</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>group</td>\n",
       "      <td>group</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>they</td>\n",
       "      <td>they</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>would</td>\n",
       "      <td>would</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>seek</td>\n",
       "      <td>seek</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>an</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>interview</td>\n",
       "      <td>interview</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Foreign</td>\n",
       "      <td>Foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>Minister</td>\n",
       "      <td>Minister</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Yukihiko</td>\n",
       "      <td>Yukihiko</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Ikeda</td>\n",
       "      <td>Ikeda</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>during</td>\n",
       "      <td>during</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>their</td>\n",
       "      <td>their</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>five-day</td>\n",
       "      <td>five-day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>visit</td>\n",
       "      <td>visit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NLTK        MINE\n",
       "0     Lawmaker    Lawmaker\n",
       "1          Kim         Kim\n",
       "2    Young-jin   Young-jin\n",
       "3           of          of\n",
       "4          the         the\n",
       "5         main        main\n",
       "6   opposition  opposition\n",
       "7     National    National\n",
       "8     Congress    Congress\n",
       "9          for         for\n",
       "10         New         New\n",
       "11    Politics    Politics\n",
       "12           ,           ,\n",
       "13      leader      leader\n",
       "14          of          of\n",
       "15         the         the\n",
       "16       group       group\n",
       "17           ,           ,\n",
       "18        said        said\n",
       "19        they        they\n",
       "20       would       would\n",
       "21        seek        seek\n",
       "22          an          an\n",
       "23   interview   interview\n",
       "24        with        with\n",
       "25     Foreign     Foreign\n",
       "26    Minister    Minister\n",
       "27    Yukihiko    Yukihiko\n",
       "28       Ikeda       Ikeda\n",
       "29      during      during\n",
       "30       their       their\n",
       "31    five-day    five-day\n",
       "32       visit       visit\n",
       "33           .           ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jordanian</td>\n",
       "      <td>Jordanian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>relief</td>\n",
       "      <td>relief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plane</td>\n",
       "      <td>plane</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>loaded</td>\n",
       "      <td>loaded</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>tents</td>\n",
       "      <td>tents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>blankets</td>\n",
       "      <td>blankets</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>food</td>\n",
       "      <td>food</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>medicine</td>\n",
       "      <td>medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>flew</td>\n",
       "      <td>flew</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Tehran</td>\n",
       "      <td>Tehran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Tuesday</td>\n",
       "      <td>Tuesday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>help</td>\n",
       "      <td>help</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>victims</td>\n",
       "      <td>victims</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>earthquake</td>\n",
       "      <td>earthquake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>Iran</td>\n",
       "      <td>Iran</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>Petra</td>\n",
       "      <td>Petra</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>news</td>\n",
       "      <td>news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>agency</td>\n",
       "      <td>agency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>reported</td>\n",
       "      <td>reported</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NLTK        MINE\n",
       "0            A           A\n",
       "1    Jordanian   Jordanian\n",
       "2       relief      relief\n",
       "3        plane       plane\n",
       "4       loaded      loaded\n",
       "5         with        with\n",
       "6        tents       tents\n",
       "7            ,           ,\n",
       "8     blankets    blankets\n",
       "9            ,           ,\n",
       "10        food        food\n",
       "11         and         and\n",
       "12    medicine    medicine\n",
       "13        flew        flew\n",
       "14          to          to\n",
       "15      Tehran      Tehran\n",
       "16          on          on\n",
       "17     Tuesday     Tuesday\n",
       "18          to          to\n",
       "19        help        help\n",
       "20     victims     victims\n",
       "21          of          of\n",
       "22         the         the\n",
       "23  earthquake  earthquake\n",
       "24          in          in\n",
       "25        Iran        Iran\n",
       "26           ,           ,\n",
       "27       Petra       Petra\n",
       "28        news        news\n",
       "29      agency      agency\n",
       "30    reported    reported\n",
       "31           .           ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chirac</td>\n",
       "      <td>Chirac</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>met</td>\n",
       "      <td>met</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kohl</td>\n",
       "      <td>Kohl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>over</td>\n",
       "      <td>over</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>dinner</td>\n",
       "      <td>dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Bonn</td>\n",
       "      <td>Bonn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>only</td>\n",
       "      <td>only</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>days</td>\n",
       "      <td>days</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ago</td>\n",
       "      <td>ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>foreign</td>\n",
       "      <td>foreign</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>ministers</td>\n",
       "      <td>ministers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Herve</td>\n",
       "      <td>Herve</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>de</td>\n",
       "      <td>de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>Charette</td>\n",
       "      <td>Charette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Klaus</td>\n",
       "      <td>Klaus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>Kinkel</td>\n",
       "      <td>Kinkel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>plan</td>\n",
       "      <td>plan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>discuss</td>\n",
       "      <td>discuss</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Europe</td>\n",
       "      <td>Europe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>meeting</td>\n",
       "      <td>meeting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Hamburg</td>\n",
       "      <td>Hamburg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>next</td>\n",
       "      <td>next</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>Monday</td>\n",
       "      <td>Monday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NLTK       MINE\n",
       "0      Chirac     Chirac\n",
       "1         met        met\n",
       "2        Kohl       Kohl\n",
       "3        over       over\n",
       "4      dinner     dinner\n",
       "5          in         in\n",
       "6        Bonn       Bonn\n",
       "7        only       only\n",
       "8          11         11\n",
       "9        days       days\n",
       "10        ago        ago\n",
       "11        and        and\n",
       "12    foreign    foreign\n",
       "13  ministers  ministers\n",
       "14      Herve      Herve\n",
       "15         de         de\n",
       "16   Charette   Charette\n",
       "17        and        and\n",
       "18      Klaus      Klaus\n",
       "19     Kinkel     Kinkel\n",
       "20       plan       plan\n",
       "21         to         to\n",
       "22    discuss    discuss\n",
       "23     Europe     Europe\n",
       "24         at         at\n",
       "25          a          a\n",
       "26    meeting    meeting\n",
       "27         in         in\n",
       "28    Hamburg    Hamburg\n",
       "29       next       next\n",
       "30     Monday     Monday\n",
       "31          .          ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>--</td>\n",
       "      <td>--Toms</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Toms</td>\n",
       "      <td>River</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>River</td>\n",
       "      <td>Board</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Board</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>of</td>\n",
       "      <td>Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Education</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>,</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>N.J.</td>\n",
       "      <td>.J</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>,</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>$</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>21.6</td>\n",
       "      <td>$21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>million</td>\n",
       "      <td>.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>school</td>\n",
       "      <td>million</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>bonds</td>\n",
       "      <td>school</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>.</td>\n",
       "      <td>bonds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>None</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NLTK       MINE\n",
       "0          --     --Toms\n",
       "1        Toms      River\n",
       "2       River      Board\n",
       "3       Board         of\n",
       "4          of  Education\n",
       "5   Education          ,\n",
       "6           ,          N\n",
       "7        N.J.         .J\n",
       "8           ,          .\n",
       "9           $          ,\n",
       "10       21.6        $21\n",
       "11    million         .6\n",
       "12     school    million\n",
       "13      bonds     school\n",
       "14          .      bonds\n",
       "15       None          ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ministry</td>\n",
       "      <td>Ministry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Executive</td>\n",
       "      <td>Executive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Secretary</td>\n",
       "      <td>Secretary</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Pedro</td>\n",
       "      <td>Pedro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Parente</td>\n",
       "      <td>Parente</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Central</td>\n",
       "      <td>Central</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Bank</td>\n",
       "      <td>Bank</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>International</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Affairs</td>\n",
       "      <td>Affairs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>chief</td>\n",
       "      <td>chief</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Gustavo</td>\n",
       "      <td>Gustavo</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Franco</td>\n",
       "      <td>Franco</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>meanwhile</td>\n",
       "      <td>meanwhile</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>also</td>\n",
       "      <td>also</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>government</td>\n",
       "      <td>government</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>mindful</td>\n",
       "      <td>mindful</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>growth</td>\n",
       "      <td>growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>consumption</td>\n",
       "      <td>consumption</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>Estado</td>\n",
       "      <td>Estado</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>said</td>\n",
       "      <td>said</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             NLTK           MINE\n",
       "0        Ministry       Ministry\n",
       "1       Executive      Executive\n",
       "2       Secretary      Secretary\n",
       "3           Pedro          Pedro\n",
       "4         Parente        Parente\n",
       "5             and            and\n",
       "6         Central        Central\n",
       "7            Bank           Bank\n",
       "8   International  International\n",
       "9         Affairs        Affairs\n",
       "10          chief          chief\n",
       "11        Gustavo        Gustavo\n",
       "12         Franco         Franco\n",
       "13              ,              ,\n",
       "14      meanwhile      meanwhile\n",
       "15              ,              ,\n",
       "16           also           also\n",
       "17           said           said\n",
       "18            the            the\n",
       "19     government     government\n",
       "20             is             is\n",
       "21        mindful        mindful\n",
       "22             of             of\n",
       "23            the            the\n",
       "24         growth         growth\n",
       "25             in             in\n",
       "26    consumption    consumption\n",
       "27              ,              ,\n",
       "28         Estado         Estado\n",
       "29           said           said\n",
       "30              .              ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NBH</td>\n",
       "      <td>NBH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>trade</td>\n",
       "      <td>trade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>deficit</td>\n",
       "      <td>deficit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan-Dec</td>\n",
       "      <td>Jan-Dec</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>$</td>\n",
       "      <td>$2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2.645</td>\n",
       "      <td>.645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>bln</td>\n",
       "      <td>bln</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>(</td>\n",
       "      <td>(Jan-Nov</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jan-Nov</td>\n",
       "      <td>$2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>$</td>\n",
       "      <td>.229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2.229</td>\n",
       "      <td>bln)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>bln</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>)</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       NLTK      MINE\n",
       "0       NBH       NBH\n",
       "1     trade     trade\n",
       "2   deficit   deficit\n",
       "3   Jan-Dec   Jan-Dec\n",
       "4         $        $2\n",
       "5     2.645      .645\n",
       "6       bln       bln\n",
       "7         (  (Jan-Nov\n",
       "8   Jan-Nov        $2\n",
       "9         $      .229\n",
       "10    2.229      bln)\n",
       "11      bln      None\n",
       "12        )      None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1330</td>\n",
       "      <td>1330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fri</td>\n",
       "      <td>Fri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USA</td>\n",
       "      <td>USA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PAYROLL</td>\n",
       "      <td>PAYROLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EMPLOY</td>\n",
       "      <td>EMPLOY</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>APR</td>\n",
       "      <td>APR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>N/F</td>\n",
       "      <td>N/F</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>K</td>\n",
       "      <td>K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>N/A</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      NLTK     MINE\n",
       "0     1330     1330\n",
       "1      Fri      Fri\n",
       "2      USA      USA\n",
       "3  PAYROLL  PAYROLL\n",
       "4   EMPLOY   EMPLOY\n",
       "5      APR      APR\n",
       "6      N/F      N/F\n",
       "7        K        K\n",
       "8      N/A      N/A\n",
       "9      N/A      N/A"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DATED</td>\n",
       "      <td>DATED:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>:</td>\n",
       "      <td>08/01/1997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>08/01/1997</td>\n",
       "      <td>FIRST</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FIRST</td>\n",
       "      <td>COUPON:</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>COUPON</td>\n",
       "      <td>02/01/1998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>:</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>02/01/1998</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         NLTK        MINE\n",
       "0       DATED      DATED:\n",
       "1           :  08/01/1997\n",
       "2  08/01/1997       FIRST\n",
       "3       FIRST     COUPON:\n",
       "4      COUPON  02/01/1998\n",
       "5           :        None\n",
       "6  02/01/1998        None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>TTL</td>\n",
       "      <td>TTL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GOLD/FORGN</td>\n",
       "      <td>GOLD/FORGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASSETS</td>\n",
       "      <td>ASSETS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JUN</td>\n",
       "      <td>JUN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>22.13</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BLN</td>\n",
       "      <td>.13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>21.80</td>\n",
       "      <td>BLN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>12.38</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>None</td>\n",
       "      <td>.80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>None</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>None</td>\n",
       "      <td>.38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          NLTK        MINE\n",
       "0          TTL         TTL\n",
       "1   GOLD/FORGN  GOLD/FORGN\n",
       "2       ASSETS      ASSETS\n",
       "3          JUN         JUN\n",
       "4        22.13          22\n",
       "5          BLN         .13\n",
       "6        21.80         BLN\n",
       "7        12.38          21\n",
       "8         None         .80\n",
       "9         None          12\n",
       "10        None         .38"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "\n",
    "rcr = ReutersCorpusReader()\n",
    "\n",
    "size = 10\n",
    "\n",
    "for sentence in rcr.sample_raw_sents(size):\n",
    "    nltk_tok = word_tokenize(sentence)\n",
    "    my_tok = token(sentence)   \n",
    "    display(pd.DataFrame(list(zip_longest(nltk_tok,my_tok)),columns=[\"NLTK\", \"MINE\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/nltk_vs_mine\n",
    "# %load ../Solutions/3/nltk_vs_mine\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "\n",
    "rcr = ReutersCorpusReader()    #Create a new reader\n",
    "\n",
    "samplesize = 10   \n",
    "\n",
    "for sentence in rcr.sample_raw_sents(samplesize): \n",
    "    nltk_toks = word_tokenize(sentence)\n",
    "    my_toks = tokenise(sentence)\n",
    "    display(pd.DataFrame(list(zip_longest(nltk_toks,my_toks)),columns=[\"NLTK\",\"MINE\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Twitter-specific Tokeniser\n",
    "The third tokeniser for you to explore is a Twitter-specific tokeniser that has been developed by [Gimpel et al.](http://ttic.uchicago.edu/~kgimpel/papers/gimpel+etal.acl11.pdf) as part of a Twitter-specific part-of-speech tagger (featured in later lab classes)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Function**: `twitter_tokenize`\n",
    "- Arguments\n",
    " - a single string, representing a sentence\n",
    "- Returns\n",
    " - a list of strings, where each string is a token within the sentence\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`twitter_tokenize` can be quite slow, so we have provided the following function to tokenise an entire sample of sentences at once.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "**Function**: `twitter_tokenize_batch`\n",
    "- Arguments\n",
    " - a list of strings, where each string represents a sentence\n",
    "- Returns\n",
    " - a list of sentences, where each sentence is a list of tokens\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- In the empty cell below, write code to run both  `twitter_tokenize` and the the NLTK tokeniser, `word_tokenize`, function on each sentence in a sample of 10 sentences from the Twitter corpus.\n",
    "- Display each sentence tokenised by the two tokenisers using the `print_lists_in_columns` function defined above.\n",
    "- Once you have done this, look for differences in the output of the two tokenisers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'word_tokenize'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-4-d49ffd04d798>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msussex_nltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtokenize\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtwitter_tokenize\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mword_tokenize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msussex_nltk\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcorpus_readers\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mTwitterCorpusReader\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtcr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTwitterCorpusReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m    \u001b[1;31m#Create a new reader\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'word_tokenize'"
     ]
    }
   ],
   "source": [
    "from sussex_nltk.tokenize import twitter_tokenize, word_tokenize\n",
    "\n",
    "from sussex_nltk.corpus_readers import TwitterCorpusReader\n",
    "\n",
    "tcr = TwitterCorpusReader()    #Create a new reader\n",
    "\n",
    "samplesize = 10   \n",
    "\n",
    "for sentence in tcr.sample_raw_sents(samplesize):\n",
    "    nltk_tok = word_tokenize(sentence)\n",
    "    twitter_tok = twitter_tokenize(sentence)\n",
    "    display(pd.DataFrame(list(zip_longest(nltk_toks,my_toks)),columns=[\"NLTK\",\"MINE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/nltk_vs_twitter\n",
    "#%load ../Solutions/3/nltk_vs_twitter\n",
    "\n",
    "from sussex_nltk.tokenize import twitter_tokenize,twitter_tokenize_batch  #import CMU tokenize functions\n",
    "from sussex_nltk.corpus_readers import TwitterCorpusReader\n",
    "\n",
    "tcr = TwitterCorpusReader()\n",
    "\n",
    "samplesize = 10\n",
    "\n",
    "for sentence in tcr.sample_raw_sents(samplesize): \n",
    "    nltk_toks = word_tokenize(sentence)\n",
    "    twit_toks = twitter_tokenize(sentence)\n",
    "    print_lists_in_columns(nltk_toks,twit_toks,\"NLTK\",\"TWIT\")\n",
    "        display(pd.DataFrame(list(zip_longest(nltk_toks,twit_toks)),columns=[\"NLTK\",\"TWIT\"]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Copy the code cell above and move the copy to below this cell. Then use both the NLTK and Twitter tokenisers on a sample of 10 sentences from the **Medline** corpus.\n",
    "- Look for situations where the  tokenisers do not tokenise appropriately.\n",
    "- Try to figure out the differences in tokenisation policies of the tokenisers.\n",
    "- Think about possible motivations for the differences in tokenisation policy, by considering how the tokens may be used in subsequent (down-stream) language processing steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>outcome</td>\n",
       "      <td>outcome</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>each</td>\n",
       "      <td>each</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>individual</td>\n",
       "      <td>individual</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>infection</td>\n",
       "      <td>infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>dependent</td>\n",
       "      <td>dependent</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>on</td>\n",
       "      <td>on</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>prompt</td>\n",
       "      <td>prompt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>recognition</td>\n",
       "      <td>recognition</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>underlying</td>\n",
       "      <td>underlying</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>valvular</td>\n",
       "      <td>valvular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>infection</td>\n",
       "      <td>infection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>institution</td>\n",
       "      <td>institution</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>antimicrobial</td>\n",
       "      <td>antimicrobial</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>therapy</td>\n",
       "      <td>therapy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             NLTK           MINE\n",
       "0             The            The\n",
       "1         outcome        outcome\n",
       "2              of             of\n",
       "3            each           each\n",
       "4      individual     individual\n",
       "5       infection      infection\n",
       "6              is             is\n",
       "7       dependent      dependent\n",
       "8              on             on\n",
       "9             the            the\n",
       "10         prompt         prompt\n",
       "11    recognition    recognition\n",
       "12             of             of\n",
       "13            the            the\n",
       "14     underlying     underlying\n",
       "15       valvular       valvular\n",
       "16      infection      infection\n",
       "17            and            and\n",
       "18            the            the\n",
       "19    institution    institution\n",
       "20             of             of\n",
       "21  antimicrobial  antimicrobial\n",
       "22        therapy        therapy\n",
       "23              .              ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>It</td>\n",
       "      <td>It</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>is</td>\n",
       "      <td>is</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>suggested</td>\n",
       "      <td>suggested</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>that</td>\n",
       "      <td>that</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>two</td>\n",
       "      <td>two</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>types</td>\n",
       "      <td>types</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>inhibitory</td>\n",
       "      <td>inhibitory</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>interneurons</td>\n",
       "      <td>interneurons</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>occur</td>\n",
       "      <td>occur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>rat</td>\n",
       "      <td>rat</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>gelatinosa</td>\n",
       "      <td>gelatinosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>one</td>\n",
       "      <td>one</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GABAergic</td>\n",
       "      <td>GABAergic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>cell</td>\n",
       "      <td>cell</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>body</td>\n",
       "      <td>body</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>lamina</td>\n",
       "      <td>lamina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>I</td>\n",
       "      <td>I</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>another</td>\n",
       "      <td>another</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>glycinergic</td>\n",
       "      <td>glycinergic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>lamina</td>\n",
       "      <td>lamina</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>III</td>\n",
       "      <td>III</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            NLTK          MINE\n",
       "0             It            It\n",
       "1             is            is\n",
       "2      suggested     suggested\n",
       "3           that          that\n",
       "4            two           two\n",
       "5          types         types\n",
       "6             of            of\n",
       "7     inhibitory    inhibitory\n",
       "8   interneurons  interneurons\n",
       "9          occur         occur\n",
       "10            in            in\n",
       "11           the           the\n",
       "12           rat           rat\n",
       "13    gelatinosa    gelatinosa\n",
       "14             ,             ,\n",
       "15           one           one\n",
       "16     GABAergic     GABAergic\n",
       "17          with          with\n",
       "18          cell          cell\n",
       "19          body          body\n",
       "20            in            in\n",
       "21        lamina        lamina\n",
       "22             I             I\n",
       "23             ,             ,\n",
       "24           and           and\n",
       "25       another       another\n",
       "26   glycinergic   glycinergic\n",
       "27            in            in\n",
       "28        lamina        lamina\n",
       "29           III           III\n",
       "30             .             ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>author</td>\n",
       "      <td>author</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>presents</td>\n",
       "      <td>presents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>an</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>observation</td>\n",
       "      <td>observation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>angiofollicular</td>\n",
       "      <td>angiofollicular</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>lymphoma</td>\n",
       "      <td>lymphoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>woman</td>\n",
       "      <td>woman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>with</td>\n",
       "      <td>with</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>a</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>rare</td>\n",
       "      <td>rare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>localization</td>\n",
       "      <td>localization</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>--</td>\n",
       "      <td>--</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>soft</td>\n",
       "      <td>soft</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>tissues</td>\n",
       "      <td>tissues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>neck</td>\n",
       "      <td>neck</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               NLTK             MINE\n",
       "0               The              The\n",
       "1            author           author\n",
       "2          presents         presents\n",
       "3                an               an\n",
       "4       observation      observation\n",
       "5                of               of\n",
       "6   angiofollicular  angiofollicular\n",
       "7          lymphoma         lymphoma\n",
       "8                in               in\n",
       "9                 a                a\n",
       "10            woman            woman\n",
       "11               of               of\n",
       "12               52               52\n",
       "13             with             with\n",
       "14                a                a\n",
       "15             rare             rare\n",
       "16     localization     localization\n",
       "17               --               --\n",
       "18               in               in\n",
       "19             soft             soft\n",
       "20          tissues          tissues\n",
       "21               of               of\n",
       "22              the              the\n",
       "23             neck             neck\n",
       "24                .                ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Muscles</td>\n",
       "      <td>Muscles</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pH</td>\n",
       "      <td>pH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>released</td>\n",
       "      <td>released</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>acid</td>\n",
       "      <td>acid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>whereas</td>\n",
       "      <td>whereas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>those</td>\n",
       "      <td>those</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>at</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>pH</td>\n",
       "      <td>pH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>did</td>\n",
       "      <td>did</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>not</td>\n",
       "      <td>not</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NLTK      MINE\n",
       "0    Muscles   Muscles\n",
       "1         at        at\n",
       "2         pH        pH\n",
       "3          8         8\n",
       "4   released  released\n",
       "5       acid      acid\n",
       "6    whereas   whereas\n",
       "7      those     those\n",
       "8         at        at\n",
       "9         pH        pH\n",
       "10         7         7\n",
       "11       did       did\n",
       "12       not       not\n",
       "13         .         ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Band</td>\n",
       "      <td>Band</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>CN-A</td>\n",
       "      <td>CN-A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>represented</td>\n",
       "      <td>represented</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>approximately</td>\n",
       "      <td>approximately</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>2%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>%</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>of</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>the</td>\n",
       "      <td>total</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>total</td>\n",
       "      <td>peptide</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>peptide</td>\n",
       "      <td>protein</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>protein</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>but</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>was</td>\n",
       "      <td>more</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>more</td>\n",
       "      <td>[</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[</td>\n",
       "      <td>32P]-phosphorylated</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>32P</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>]</td>\n",
       "      <td>patients</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-phosphorylated</td>\n",
       "      <td>than</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>patients</td>\n",
       "      <td>controls</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>than</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>in</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>controls</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               NLTK                 MINE\n",
       "0              Band                 Band\n",
       "1              CN-A                 CN-A\n",
       "2       represented          represented\n",
       "3     approximately        approximately\n",
       "4                 2                   2%\n",
       "5                 %                   of\n",
       "6                of                  the\n",
       "7               the                total\n",
       "8             total              peptide\n",
       "9           peptide              protein\n",
       "10          protein                  but\n",
       "11              but                  was\n",
       "12              was                 more\n",
       "13             more                    [\n",
       "14                [  32P]-phosphorylated\n",
       "15              32P                   in\n",
       "16                ]             patients\n",
       "17  -phosphorylated                 than\n",
       "18               in                   in\n",
       "19         patients             controls\n",
       "20             than                    .\n",
       "21               in                 None\n",
       "22         controls                 None\n",
       "23                .                 None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>chemosensitivity</td>\n",
       "      <td>chemosensitivity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>human</td>\n",
       "      <td>human</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>melanoma</td>\n",
       "      <td>melanoma</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>cells</td>\n",
       "      <td>cells</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>has</td>\n",
       "      <td>has</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>been</td>\n",
       "      <td>been</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>studied</td>\n",
       "      <td>studied</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>before</td>\n",
       "      <td>before</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>after</td>\n",
       "      <td>after</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>continuous</td>\n",
       "      <td>continuous</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>in</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>vitro</td>\n",
       "      <td>vitro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>culture</td>\n",
       "      <td>culture</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                NLTK              MINE\n",
       "0                The               The\n",
       "1   chemosensitivity  chemosensitivity\n",
       "2                 of                of\n",
       "3              human             human\n",
       "4           melanoma          melanoma\n",
       "5              cells             cells\n",
       "6                has               has\n",
       "7               been              been\n",
       "8            studied           studied\n",
       "9             before            before\n",
       "10               and               and\n",
       "11             after             after\n",
       "12        continuous        continuous\n",
       "13                in                in\n",
       "14             vitro             vitro\n",
       "15           culture           culture\n",
       "16                 .                 ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Veterans</td>\n",
       "      <td>Veterans</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>administration</td>\n",
       "      <td>administration's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>'s</td>\n",
       "      <td>Department</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Department</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>of</td>\n",
       "      <td>Medical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Medical</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>and</td>\n",
       "      <td>Surgery</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Surgery</td>\n",
       "      <td>includes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>includes</td>\n",
       "      <td>in</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>in</td>\n",
       "      <td>its</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>its</td>\n",
       "      <td>Graduate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Graduate</td>\n",
       "      <td>Engineer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Engineer</td>\n",
       "      <td>Training</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Training</td>\n",
       "      <td>Program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Program</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>a</td>\n",
       "      <td>special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>special</td>\n",
       "      <td>program</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>program</td>\n",
       "      <td>for</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>for</td>\n",
       "      <td>Biomedical</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Biomedical</td>\n",
       "      <td>Engineers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Engineers</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>.</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              NLTK              MINE\n",
       "0              The               The\n",
       "1         Veterans          Veterans\n",
       "2   administration  administration's\n",
       "3               's        Department\n",
       "4       Department                of\n",
       "5               of           Medical\n",
       "6          Medical               and\n",
       "7              and           Surgery\n",
       "8          Surgery          includes\n",
       "9         includes                in\n",
       "10              in               its\n",
       "11             its          Graduate\n",
       "12        Graduate          Engineer\n",
       "13        Engineer          Training\n",
       "14        Training           Program\n",
       "15         Program                 a\n",
       "16               a           special\n",
       "17         special           program\n",
       "18         program               for\n",
       "19             for        Biomedical\n",
       "20      Biomedical         Engineers\n",
       "21       Engineers                 .\n",
       "22               .              None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Stimulation</td>\n",
       "      <td>Stimulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lysosomal</td>\n",
       "      <td>lysosomal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>beta-glucuronidase</td>\n",
       "      <td>beta-glucuronidase</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>can</td>\n",
       "      <td>can</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>explain</td>\n",
       "      <td>explain</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>this</td>\n",
       "      <td>this</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fluid</td>\n",
       "      <td>fluid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>accumulation</td>\n",
       "      <td>accumulation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NLTK                MINE\n",
       "0         Stimulation         Stimulation\n",
       "1                  of                  of\n",
       "2           lysosomal           lysosomal\n",
       "3  beta-glucuronidase  beta-glucuronidase\n",
       "4                 can                 can\n",
       "5             explain             explain\n",
       "6                this                this\n",
       "7               fluid               fluid\n",
       "8        accumulation        accumulation\n",
       "9                   .                   ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>immunostimulating</td>\n",
       "      <td>immunostimulating</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>agents</td>\n",
       "      <td>agents</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>were</td>\n",
       "      <td>were</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>detrimental</td>\n",
       "      <td>detrimental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>to</td>\n",
       "      <td>to</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>progeny</td>\n",
       "      <td>progeny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>,</td>\n",
       "      <td>,</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>but</td>\n",
       "      <td>but</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>the</td>\n",
       "      <td>the</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>immunosupprissive</td>\n",
       "      <td>immunosupprissive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>drugs</td>\n",
       "      <td>drugs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>caused</td>\n",
       "      <td>caused</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>an</td>\n",
       "      <td>an</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>increased</td>\n",
       "      <td>increased</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>percentage</td>\n",
       "      <td>percentage</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>foetal</td>\n",
       "      <td>foetal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>deaths</td>\n",
       "      <td>deaths</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>and</td>\n",
       "      <td>and</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>foetoplacental</td>\n",
       "      <td>foetoplacental</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>growth</td>\n",
       "      <td>growth</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>retardation</td>\n",
       "      <td>retardation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NLTK               MINE\n",
       "0                None               None\n",
       "1                  of                 of\n",
       "2                 the                the\n",
       "3   immunostimulating  immunostimulating\n",
       "4              agents             agents\n",
       "5                were               were\n",
       "6         detrimental        detrimental\n",
       "7                  to                 to\n",
       "8                 the                the\n",
       "9             progeny            progeny\n",
       "10                  ,                  ,\n",
       "11                but                but\n",
       "12                the                the\n",
       "13  immunosupprissive  immunosupprissive\n",
       "14              drugs              drugs\n",
       "15             caused             caused\n",
       "16                 an                 an\n",
       "17          increased          increased\n",
       "18         percentage         percentage\n",
       "19                 of                 of\n",
       "20             foetal             foetal\n",
       "21             deaths             deaths\n",
       "22                and                and\n",
       "23     foetoplacental     foetoplacental\n",
       "24             growth             growth\n",
       "25        retardation        retardation\n",
       "26                  .                  ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NLTK</th>\n",
       "      <th>MINE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The</td>\n",
       "      <td>The</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frequency</td>\n",
       "      <td>frequency</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>of</td>\n",
       "      <td>of</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>emetic</td>\n",
       "      <td>emetic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>sequelae</td>\n",
       "      <td>sequelae</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>was</td>\n",
       "      <td>was</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>high</td>\n",
       "      <td>high</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        NLTK       MINE\n",
       "0        The        The\n",
       "1  frequency  frequency\n",
       "2         of         of\n",
       "3     emetic     emetic\n",
       "4   sequelae   sequelae\n",
       "5        was        was\n",
       "6       high       high\n",
       "7          .          ."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sussex_nltk.tokenize import twitter_tokenize,twitter_tokenize_batch\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sussex_nltk.corpus_readers import MedlineCorpusReader\n",
    "\n",
    "mcr = MedlineCorpusReader()    #Create a new reader\n",
    "\n",
    "samplesize = 10   \n",
    "\n",
    "for sentence in mcr.sample_raw_sents(samplesize):\n",
    "    nltk_toks = word_tokenize(sentence)\n",
    "    twitter_toks = twitter_tokenize(sentence)\n",
    "    display(pd.DataFrame(list(zip_longest(nltk_toks,twitter_toks)),columns=[\"NLTK\",\"MINE\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/nltk_vs_twitter_medline\n",
    "# %load ../Solutions/3/nltk_vs_twitter_medline\n",
    "\n",
    "from sussex_nltk.tokenize import twitter_tokenize,twitter_tokenize_batch  #import CMU tokenize functions\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sussex_nltk.corpus_readers import MedlineCorpusReader\n",
    "\n",
    "mcr = MedlineCorpusReader()    #Create a new reader\n",
    "\n",
    "samplesize = 10   \n",
    "\n",
    "for sentence in mcr.sample_raw_sents(samplesize): \n",
    "    nltk_toks = word_tokenize(sentence)\n",
    "    twit_toks = twitter_tokenize(sentence)\n",
    "    display(pd.DataFrame(list(zip_longest(nltk_toks,twit_toks)),columns=[\"NLTK\",\"TWIT\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalising text and removing unimportant tokens\n",
    "In this next section we will consider several methods that pre-process (tokenised) text in ways that are sometimes helpful to 'downstream' processing."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Number and case normalisation\n",
    "Without any kind of normalisation, the tokens `\"help\"` and `\"Help\"` are two distinct types. In some contexts you may not want to distinguish them.\n",
    "\n",
    "Another example, is that `\"1998\"` and `\"1999\"` count as distinct types. There are situations where there is no need to distinction between different numbers.\n",
    "\n",
    "The following code performs case normalisation and replaces tokens that consist of digits by \"NUM\". \n",
    "- Python provides a [number of functions](http://docs.python.org/library/stdtypes.html#string-methods), which you can call in order to analyse their content, or produce new strings from them.\n",
    "- The code uses [list comprehension](http://docs.python.org/tutorial/datastructures.html#list-comprehensions) to build a new list by looping through and filtering items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'cake', 'is', 'a', 'lie']\n",
      "['in', 'the', 'year', 'NUM', 'of', 'the', 'fourth', 'age', ',', 'after', 'NUM', 'years', 'as', 'king', ',', 'aragorn', 'died', 'at', 'the', 'age', 'of', 'NUM']\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"The\",\"cake\",\"is\",\"a\",\"LIE\"]      #a list of tokens, some of which contain uppercase letters\n",
    "print([token.lower() for token in tokens])   #print newly created list of all lowercase tokens\n",
    "\n",
    "numbers = ['in', 'the', 'year', '120', 'of', 'the', 'fourth', 'age', ',', 'after', '120', 'years', 'as', 'king', ',' , 'aragorn', 'died', 'at', 'the', 'age', 'of', '210']\n",
    "print([\"NUM\" if token.isdigit() else token for token in numbers])  #replace all number tokens with \"NUM\" in a new list of tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- In the empty cell below, write code that normalises tokens such as `\"4th\"`, `\"1st\"` and `\"22nd\"` to `\"Nth\"`.\n",
    "- Try to adapt this code from the cell above: `[\"NUM\" if token.isdigit() else token for token in numbers]`\n",
    "- Test your code on the list `[\"The\", \"1st\", \"and\", \"2nd\", \"placed\", \"runners\", \"lapped\", \"the\", \"5th\",\".\"]`. \n",
    "- Check that the token `\"and\"` isn't changed to `\"Nth\"`.\n",
    "- You will find [this page](http://docs.python.org/library/stdtypes.html#string-methods) useful.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ALNUM', 'ALNUM', 'ALNUM', 'Nth']\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"4th\", \"1st\", \"22nd\", \"Nth\"]\n",
    "print([\"ALNUM\" if not token.isalpha() else token for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'ALNUM', 'and', 'ALNUM', 'placed', 'runners', 'lapped', 'the', 'ALNUM', 'ALNUM']\n"
     ]
    }
   ],
   "source": [
    "tokens = [\"The\", \"1st\", \"and\", \"2nd\", \"placed\", \"runners\", \"lapped\", \"the\", \"5th\",\".\"]\n",
    "print([\"ALNUM\" if not token.isalpha() else token for token in tokens])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['The', 'Nth', 'and', 'Nth', 'placed', 'runners', 'lapped', 'the', 'Nth', '.']\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/normalise_to_Nth\n",
    "#%load ../Solutions/3/normalise_to_Nth\n",
    "\n",
    "tokens = [\"The\", \"1st\", \"and\", \"2nd\", \"placed\", \"runners\", \"lapped\", \"the\", \"5th\",\".\"]\n",
    "print([\"Nth\" if (token.endswith((\"nd\",\"st\",\"th\")) and token[:-2].isdigit()) else token for token in tokens])  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Complete the code in the cell below. You have just two lines to complete. The goal is to use a large sample of the Reuters corpus to establish the extent to which vocabulary size is reduced when number and case normalisation is applied.\n",
    "- For each of the two incomplete lines you should use nested list comprehensions. This is described in Section 5.1.4 in [this document](http://docs.python.org/tutorial/datastructures.html#list-comprehensions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisation produced a 13.46% reduction in vocabulary size from 19421 to 16807\n"
     ]
    }
   ],
   "source": [
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def vocabulary_size(sentences):\n",
    "    tok_counts = collections.defaultdict(int)\n",
    "    for sentence in sentences: \n",
    "        for token in sentence:\n",
    "            tok_counts[token] += 1\n",
    "    return len(tok_counts.keys())\n",
    "\n",
    "rcr = ReutersCorpusReader()    \n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "raw_sentences = rcr.sample_raw_sents(sample_size)\n",
    "tokenised_sentences = [word_tokenize(sentence) for sentence in raw_sentences]\n",
    "\n",
    "############################################\n",
    "lowered_sentences = [[token.lower() for token in sentence] for sentence in tokenised_sentences]\n",
    "normalised_sentences = [[\"num\" if token.isdigit() else token for token in sentence] for sentence in lowered_sentences]\n",
    "############################################\n",
    "\n",
    "raw_vocab_size = vocabulary_size(tokenised_sentences)\n",
    "normalised_vocab_size = vocabulary_size(normalised_sentences)\n",
    "print(\"Normalisation produced a {0:.2f}% reduction in vocabulary size from {1} to {2}\".format(\n",
    "    100*(raw_vocab_size - normalised_vocab_size)/raw_vocab_size,raw_vocab_size,normalised_vocab_size))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisation produced a 13.91% reduction in vocabulary size from 19294 to 16610\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/impact_of_normalisation\n",
    "#%load ../Solutions/3/impact_of_normalisation\n",
    "\n",
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "def vocabulary_size(sentences):\n",
    "    tok_counts = collections.defaultdict(int)\n",
    "    for sentence in sentences: \n",
    "        for token in sentence:\n",
    "            tok_counts[token] += 1\n",
    "    return len(tok_counts.keys())\n",
    "\n",
    "rcr = ReutersCorpusReader()    \n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "raw_sentences = rcr.sample_raw_sents(sample_size)\n",
    "tokenised_sentences = [word_tokenize(sentence) for sentence in raw_sentences]\n",
    "lowered_sentences = [[token.lower() for token in sentence] for sentence in tokenised_sentences]\n",
    "normalised_sentences = [[\"NUM\" if token.isdigit() else token for token in sentence] for sentence in lowered_sentences]\n",
    "raw_vocab_size = vocabulary_size(tokenised_sentences)\n",
    "normalised_vocab_size = vocabulary_size(normalised_sentences)\n",
    "print(\"Normalisation produced a {0:.2f}% reduction in vocabulary size from {1} to {2}\".format(\n",
    "    100*(raw_vocab_size - normalised_vocab_size)/raw_vocab_size,raw_vocab_size,normalised_vocab_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stemming\n",
    "A considerable amount of the lexical variation found in documents results from the use of morphological variants which we might not wish to distinguish - e.g. when determining the topic of a document. An easy way to remove these varied forms is to use a stemmer. NLTK includes a number of stemmers in the `nltk.stem` package.\n",
    "- [NLTK stem module API](http://nltk.org/api/nltk.stem.html)\n",
    "\n",
    "- [NLTK Porter stemmer](http://nltk.org/api/nltk.stem.html?highlight=stemmer#nltk.stem.porter.PorterStemmer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- Complete the code below to show how the NLTK implementation of the Porter stemmer in `nltk.stem.porter.PorterStemmer` stems a sample of sentences in the Reuters corpus. All you need to do is to provide the missing first two arguments to the call to `print_lists_in_columns`.\n",
    "- Have a close look at the differences between the columns. This will give you a good indication of what the stemmer does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'print_lists_in_columns' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-eea2e95fde87>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0msentence\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mtokenised_sentences\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m     \u001b[0mprint_lists_in_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_sentences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mtokenised_sentences\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"BEFORE\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m\"AFTER\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'print_lists_in_columns' is not defined"
     ]
    }
   ],
   "source": [
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "rcr = ReutersCorpusReader() \n",
    "st = PorterStemmer()\n",
    "\n",
    "sample_size = 10\n",
    "\n",
    "raw_sentences = rcr.sample_raw_sents(sample_size)\n",
    "tokenised_sentences = [word_tokenize(sentence) for sentence in raw_sentences]\n",
    "\n",
    "for sentence in tokenised_sentences:\n",
    "    print_lists_in_columns(sentence,[st.stem(token) for token in sentence],\"BEFORE\",\"AFTER\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      BEFORE   AFTER\n",
      "0   Seasonal  season\n",
      "1      Loans    loan\n",
      "2        ...     ...\n",
      "3        ...     ...\n",
      "4        ...     ...\n",
      "5        ...     ...\n",
      "6        ...     ...\n",
      "7        ...     ...\n",
      "8        295     295\n",
      "9         up      up\n",
      "10       ...     ...\n",
      "11       ...     ...\n",
      "12       ...     ...\n",
      "13       ...     ...\n",
      "14        74      74\n",
      "      BEFORE    AFTER\n",
      "0       This      thi\n",
      "1       year     year\n",
      "2          ,        ,\n",
      "3       hits      hit\n",
      "4       from     from\n",
      "5        the      the\n",
      "6      Spice    spice\n",
      "7      Girls     girl\n",
      "8        and      and\n",
      "9      other    other\n",
      "10    Virgin   virgin\n",
      "11      acts      act\n",
      "12      like     like\n",
      "13       the      the\n",
      "14  Smashing    smash\n",
      "15  Pumpkins  pumpkin\n",
      "16         ,        ,\n",
      "17  Scarface  scarfac\n",
      "18       and      and\n",
      "19      Blur     blur\n",
      "20      have     have\n",
      "21    helped     help\n",
      "22     boost    boost\n",
      "23       EMI      emi\n",
      "24        's       's\n",
      "25     sales     sale\n",
      "26         .        .\n",
      "   BEFORE   AFTER\n",
      "0       $       $\n",
      "1   Price   price\n",
      "2  99.669  99.669\n",
      "3       )       )\n",
      "         BEFORE     AFTER\n",
      "0            --        --\n",
      "1      Maricopa  maricopa\n",
      "2        County    counti\n",
      "3     Community    commun\n",
      "4       College    colleg\n",
      "5             ,         ,\n",
      "6         Ariz.     ariz.\n",
      "7             ,         ,\n",
      "8             $         $\n",
      "9        124.25    124.25\n",
      "10      million   million\n",
      "11      General     gener\n",
      "12  Obligations     oblig\n",
      "13            (         (\n",
      "14          GOs        go\n",
      "15            )         )\n",
      "16            .         .\n",
      "               BEFORE            AFTER\n",
      "0                  ``               ``\n",
      "1                Most             most\n",
      "2                  of               of\n",
      "3                 our              our\n",
      "4              people            peopl\n",
      "5                will             will\n",
      "6            continue          continu\n",
      "7                  to               to\n",
      "8                make             make\n",
      "9                 the              the\n",
      "10             strong           strong\n",
      "11           products          product\n",
      "12                and              and\n",
      "13                the              the\n",
      "14             strong           strong\n",
      "15             brands            brand\n",
      "16                 ''               ''\n",
      "17               that             that\n",
      "18                are              are\n",
      "19                now              now\n",
      "20              being               be\n",
      "21       manufactured       manufactur\n",
      "22                 by               by\n",
      "23               both             both\n",
      "24          companies          compani\n",
      "25                  ,                ,\n",
      "26               said             said\n",
      "27              James             jame\n",
      "28              River            river\n",
      "29              chief            chief\n",
      "30          executive           execut\n",
      "31            officer            offic\n",
      "32              Miles             mile\n",
      "33              Marsh            marsh\n",
      "34                 at               at\n",
      "35                  a                a\n",
      "36              press            press\n",
      "37         conference           confer\n",
      "38                 to               to\n",
      "39            discuss          discuss\n",
      "40                the              the\n",
      "41  earlier-announced  earlier-announc\n",
      "42             merger           merger\n",
      "43                  .                .\n",
      "   BEFORE  AFTER\n",
      "0  SERIES   seri\n",
      "1   1997A  1997a\n",
      "     BEFORE     AFTER\n",
      "0        ``        ``\n",
      "1        We        We\n",
      "2      want      want\n",
      "3        to        to\n",
      "4    reform    reform\n",
      "5       the       the\n",
      "6  indirect  indirect\n",
      "7       tax       tax\n",
      "8      base      base\n",
      "9         .         .\n",
      "    BEFORE  AFTER\n",
      "0       UK     UK\n",
      "1       's     's\n",
      "2   Clarke  clark\n",
      "3     says    say\n",
      "4     does    doe\n",
      "5      not    not\n",
      "6     need   need\n",
      "7       to     to\n",
      "8    raise   rais\n",
      "9      tax    tax\n",
      "10       .      .\n",
      "        BEFORE    AFTER\n",
      "0           M1       M1\n",
      "1           --       --\n",
      "2     Currency  currenc\n",
      "3           in       in\n",
      "4  circulation   circul\n",
      "5            +        +\n",
      "6       Demand   demand\n",
      "7     deposits  deposit\n",
      "   BEFORE AFTER\n",
      "0      --    --\n",
      "1      --    --\n",
      "2      --    --\n",
      "3      --    --\n",
      "4      --    --\n",
      "5      --    --\n",
      "6      --    --\n",
      "7      --    --\n",
      "8      --    --\n",
      "9      --    --\n",
      "10     --    --\n",
      "11     --    --\n",
      "12     --    --\n",
      "13     --    --\n",
      "14     --    --\n",
      "15     --    --\n",
      "16     --    --\n",
      "17     --    --\n",
      "18     --    --\n",
      "19     --    --\n",
      "20     --    --\n",
      "21     --    --\n",
      "22     --    --\n",
      "23     --    --\n",
      "24     --    --\n",
      "25     --    --\n",
      "26     --    --\n",
      "27     --    --\n",
      "28     --    --\n",
      "29      -     -\n"
     ]
    }
   ],
   "source": [
    "# %load solutions/show_stemmer_sample\n",
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "rcr = ReutersCorpusReader() \n",
    "st = PorterStemmer()\n",
    "\n",
    "sample_size = 10\n",
    "\n",
    "raw_sentences = rcr.sample_raw_sents(sample_size)\n",
    "tokenised_sentences = [word_tokenize(sentence) for sentence in raw_sentences]\n",
    "\n",
    "for sentence in tokenised_sentences:\n",
    "    df = pd.DataFrame(list(zip_longest(sentence,[st.stem(token) for token in sentence])),columns=[\"BEFORE\",\"AFTER\"])\n",
    "    print(df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- By looking at the impact on a large sample of the Reuters corpus, establish the extent to which vocabulary size is reduced by stemming.\n",
    "- Write code to do this in the empty cell below. You should be able to re-use a lot of the code from the code you used when measuring the impact of lower case and number normalisation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load solutions/impact_of_stemming\n",
    "from sussex_nltk.corpus_readers import ReutersCorpusReader\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "def vocabulary_size(sentences):\n",
    "    tok_counts = collections.defaultdict(int)\n",
    "    for sentence in sentences: \n",
    "        for token in sentence:\n",
    "            tok_counts[token] += 1\n",
    "    return len(tok_counts.keys())\n",
    "\n",
    "rcr = ReutersCorpusReader()    \n",
    "st = PorterStemmer()\n",
    "\n",
    "sample_size = 10000\n",
    "\n",
    "raw_sentences = rcr.sample_raw_sents(sample_size)\n",
    "tokenised_sentences = [word_tokenize(sentence) for sentence in raw_sentences]\n",
    "stemmed_sentences = [[st.stem(token) for token in sentence] for sentence in tokenised_sentences]\n",
    "raw_vocab_size = vocabulary_size(tokenised_sentences)\n",
    "stemmed_vocab_size = vocabulary_size(stemmed_sentences)\n",
    "print(\"Stemming produced a {0:.2f}% reduction in vocabulary size from {1} to {2}\".format(\n",
    "    100*(raw_vocab_size - stemmed_vocab_size)/raw_vocab_size,raw_vocab_size,stemmed_vocab_size))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation and stop-word removal\n",
    "A stopword is a word that occurs so often that it loses its usefulness in some tasks. We may get more meaningful information from our corpus analysis if we remove stopwords and punctuation.\n",
    "\n",
    "The code below takes a list of tokens and creates a new list, which contains only those strings which are alphabetic and non-stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "stopwords = stopwords.words('english')\n",
    "filtered_tokens = [w for w in tokens if w.isalpha() and w not in stopwords]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: `isalpha` only returns `True` if the string is entirely composed of alphabet characters. If you want a function to return `True` even when a word contains digits, then you should use `isalnum`.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercise\n",
    "- In the empty cell below, write code that looks at a large sample of the Medline corpus, establishing what proportion of tokens are stop-words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# uncomment the next line and then run the cell to load a solution\n",
    "# %load solutions/impact_of_stopword_removal"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
